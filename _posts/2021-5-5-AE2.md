---
layout: post
title: AE2-Nets Autoencoder in Autoencoder Networks
date: 2021-05-05
author: Rasin
header-img: img/abstract-oil-painting-1.jpg
catalog: true
tags:
  - Clustering
  - Autoencoder
  - Neural Network
  - Paper Reading
---

# 简介

现实世界中的数据通常使用多种形式或多种类型的描述符来描述，这些描述符被视为多视图。由于传感器或特征提取器的多样性，这些不同的视图通常高度异构。因此，目前已经提出了许多方法来共同利用多种类型的特征或数据的多种形式。

大多数现有的多视图学习算法都集中在分类或聚类上。将不同的视图集成为一个完整的表示形式对于下游任务至关重要，因为统一的表示形式很容易被现成的算法利用。尽管如此，但是由于不同视图之间存在复杂的关联性，因此共同探索多个视图是一项长期的挑战。学习通用表示的代表性方式是规范相关分析（Canonical Correlation Analysis，CCA），它搜索两个投影以将两个视图映射到一个低维的公共子空间，在该空间中两个视图之间的线性相关性被最大化。然后，学习到的表示可以用于后续任务。

为了解决线性情况以外的更复杂的相关性，核CCA（KCCA）引入了核技术。此外，深度CCA（DCCA）提出使用深度神经网络学习高度非线性的映射，以搜索可以最大化两个视图之间的相关性的公共空间。除了基于CCA的方法外，偏最小二乘（PLS）回归还可以将样本从一个视图回归到另一个视图，灵活的多视图联合降维算法（MDcR）可以最大化核空间中不同视图之间的相关性。

现有算法还有几个主要问题。 首先，先前的算法通常在不同的视图之间存在足够的相关性这一基本假设下，将不同的视图投影到公共空间上。 但是，实际上，相关性（一致性）和独立性（互补性）并存，并且要自动平衡它们是有挑战的。因此，现有算法要么以最大化相关性以实现一致性，要么以最大化独立性以实现互补性。 其次，现有算法通常将每个视图投影到一个低维空间，然后将所有视图组合到后续任务中，而不是学习通用的低维表示，这使其成为表示学习中的两步方式。 因此，在本文中，我们提出了自编码器网络中的自编码器`AE2-Nets`，其目的是将来自异构视图的固有信息自动编码为一个完整的表示形式，并自适应地平衡不同视图之间的互补性和一致性。 

提出的模型的关键优势在于采用新型嵌套自动编码器网络的联合特定于视图的编码和多视图编码。 由内部AE网络编码的特定视图表示负责重构原始输入，而由外部AE网络编码的多视图表示可以通过每个单个视图的内部AE网络重构编码表示。 本文的主要贡献概括如下： 

1. 我们提出了一种新颖的无监督多视图表示学习框架-用于异构数据的自编码器网络中的自编码器 `AE2-Nets`，它可以将多个异构视图灵活地集成到一个完整的表示中。

2. 新颖的嵌套自动编码器网络可以联合执行特定于视图的表示学习和多视图表示学习-内部自动编码器网络有效地从每个单个视图中提取信息，而外部自动编码器网络则对退化过程进行建模，以将每个单个视图中的固有信息编码为 常见的完整表示形式。

3. 大量的实验结果验证了所提出的`AE2-Net`在分类和聚类任务的各种基准数据集上的有效性。

# 自编码器网络中的自编码器

